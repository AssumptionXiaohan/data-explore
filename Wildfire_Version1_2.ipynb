{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Wildfire_Version1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AssumptionXiaohan/data-explore/blob/master/Wildfire_Version1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkTasvOgTcMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUv_6JmxTcMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split train test data\n",
        "dir =  '/Users/casey/caseyzzz/data-explore/Caseyzzz/'\n",
        "import os\n",
        "os.chdir (dir)\n",
        "torch.set_default_dtype(torch.double)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvc8WHedTcMu",
        "colab_type": "text"
      },
      "source": [
        "# Better Data\n",
        "## - More data:\n",
        "1. add all 25 channels\n",
        "\n",
        "2. Fire: No_Fire = 1:5\n",
        "\n",
        "3. More Fire Data\n",
        "\n",
        "4. flip + rotate\n",
        "\n",
        "5. Label into two column(Fire, No-Fire)\n",
        "\n",
        "## - Preprocessing:\n",
        "1. Nomarlization -> Visualize and then find better way to normalize\n",
        "\n",
        "2. Null -> 0, negative -> 0 \n",
        "\n",
        "\n",
        "# Better Model\n",
        "## - Change Plan\n",
        "1. one more fc and conv\n",
        "\n",
        "2. Kernal size change\n",
        "\n",
        "3. Adam as optimizer\n",
        "\n",
        "4. visualize the weigth to analyze the model\n",
        "\n",
        "5. ensitivity\n",
        "\n",
        "## - Change Log\n",
        "1. training time from 10 -> 200\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sOJBju7TcMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing null and negative data into 0\n",
        "#Count null value for pixel\n",
        "def na_negative_data(trainset):\n",
        "    for i in range(len(trainset)):\n",
        "        feature=trainset.iloc[i,:-1]\n",
        "        for j in range(len(feature)):\n",
        "            if pd.isna(feature[j]):\n",
        "                feature[j] = 0\n",
        "            if feature[j] < 0:\n",
        "                feature[j] = 0\n",
        "    return trainset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olmMxxO2TcMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "ds = pd.read_csv('dataset.csv',header=None)\n",
        "train, test = train_test_split(ds, test_size = 0.2,random_state=42)\n",
        "\n",
        "train = na_negative_data(train)\n",
        "test = na_negative_data(test)\n",
        "\n",
        "#label = train.iloc[:,-1]\n",
        "#temp0 = 1-label\n",
        "#train.insert(train.shape[1],'385',temp0)\n",
        "\n",
        "#t_label = test.iloc[:,-1]\n",
        "#temp1 = 1-t_label\n",
        "#test.insert(test.shape[1],'385',temp1)\n",
        "\n",
        "train.to_csv('train.csv', index = None,header = None)\n",
        "test.to_csv('test.csv',index = None,header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JLUT-Fg_TcM1",
        "colab_type": "code",
        "colab": {},
        "outputId": "03e7b401-97a7-46a3-8822-1b2b71a7a6e5"
      },
      "source": [
        "df0 = pd.read_csv('train.csv',header = None)\n",
        "df0.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "      <td>8610.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.188445</td>\n",
              "      <td>1.229821</td>\n",
              "      <td>1.260499</td>\n",
              "      <td>1.287377</td>\n",
              "      <td>1.307751</td>\n",
              "      <td>1.329772</td>\n",
              "      <td>1.354190</td>\n",
              "      <td>1.377502</td>\n",
              "      <td>1.213132</td>\n",
              "      <td>1.238609</td>\n",
              "      <td>...</td>\n",
              "      <td>4.472125</td>\n",
              "      <td>4.175958</td>\n",
              "      <td>4.175958</td>\n",
              "      <td>4.264808</td>\n",
              "      <td>4.235192</td>\n",
              "      <td>4.353659</td>\n",
              "      <td>4.383275</td>\n",
              "      <td>4.442509</td>\n",
              "      <td>4.531359</td>\n",
              "      <td>0.329965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.346568</td>\n",
              "      <td>7.574832</td>\n",
              "      <td>7.770183</td>\n",
              "      <td>7.927579</td>\n",
              "      <td>8.050399</td>\n",
              "      <td>8.206731</td>\n",
              "      <td>8.364756</td>\n",
              "      <td>8.481319</td>\n",
              "      <td>7.499417</td>\n",
              "      <td>7.628592</td>\n",
              "      <td>...</td>\n",
              "      <td>33.474202</td>\n",
              "      <td>32.365914</td>\n",
              "      <td>32.365914</td>\n",
              "      <td>32.702626</td>\n",
              "      <td>32.590802</td>\n",
              "      <td>33.035668</td>\n",
              "      <td>33.145885</td>\n",
              "      <td>33.365148</td>\n",
              "      <td>33.691173</td>\n",
              "      <td>0.470227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>255.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 385 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0            1            2            3            4    \\\n",
              "count  8610.000000  8610.000000  8610.000000  8610.000000  8610.000000   \n",
              "mean      1.188445     1.229821     1.260499     1.287377     1.307751   \n",
              "std       7.346568     7.574832     7.770183     7.927579     8.050399   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000015     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000015     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000015     0.000000     0.000000     0.000000   \n",
              "max     255.000000   255.000000   255.000000   255.000000   255.000000   \n",
              "\n",
              "               5            6            7            8            9    ...  \\\n",
              "count  8610.000000  8610.000000  8610.000000  8610.000000  8610.000000  ...   \n",
              "mean      1.329772     1.354190     1.377502     1.213132     1.238609  ...   \n",
              "std       8.206731     8.364756     8.481319     7.499417     7.628592  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000015     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000015     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000015     0.000000     0.000000  ...   \n",
              "max     255.000000   255.000000   255.000000   255.000000   255.000000  ...   \n",
              "\n",
              "               375          376          377          378          379  \\\n",
              "count  8610.000000  8610.000000  8610.000000  8610.000000  8610.000000   \n",
              "mean      4.472125     4.175958     4.175958     4.264808     4.235192   \n",
              "std      33.474202    32.365914    32.365914    32.702626    32.590802   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max     255.000000   255.000000   255.000000   255.000000   255.000000   \n",
              "\n",
              "               380          381          382          383          384  \n",
              "count  8610.000000  8610.000000  8610.000000  8610.000000  8610.000000  \n",
              "mean      4.353659     4.383275     4.442509     4.531359     0.329965  \n",
              "std      33.035668    33.145885    33.365148    33.691173     0.470227  \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000     1.000000  \n",
              "max     255.000000   255.000000   255.000000   255.000000     1.000000  \n",
              "\n",
              "[8 rows x 385 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qinOqM4TcM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class WildfireDataset(Dataset):\n",
        "    \"\"\"Wildfire Preset 1 dataset.\"\"\"\n",
        "    def __init__(self, file_path, transform=None):\n",
        "        self.data = pd.read_csv(file_path,header = None)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load image as ndarray type (Height * Width * Channels)\n",
        "        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n",
        "        # in this example, i don't use ToTensor() method of torchvision.transforms\n",
        "        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n",
        "        image = self.data.iloc[index,:-1].to_numpy().reshape((6, 8, 8))\n",
        "        label = self.data.iloc[index,-1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            feature = self.transform(image)\n",
        "        return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJAHXFqMTcM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize dataset class\n",
        "train_dataset = WildfireDataset('train.csv', transform=torch.from_numpy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAl6eqMTcM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load train_data\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "f-PxxSbfTcNB",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa5ee139-94e3-4422-e8a2-a102cbb798b9"
      },
      "source": [
        "train_iter = iter(train_loader)\n",
        "print(type(train_iter))\n",
        "images, labels = train_iter.next()\n",
        "print('images shape on batch size = {}'.format(images.size()))\n",
        "print('labels shape on batch size = {}'.format(labels.size()))\n",
        "print(type(images))\n",
        "print(images.dtype)\n",
        "print(type(labels))\n",
        "print(labels.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
            "images shape on batch size = torch.Size([4, 6, 8, 8])\n",
            "labels shape on batch size = torch.Size([4])\n",
            "<class 'torch.Tensor'>\n",
            "torch.float64\n",
            "<class 'torch.Tensor'>\n",
            "torch.float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0cE0pRzTcNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR Model for Wildfire\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(6, 32, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 1)\n",
        "        #self.conv2 = nn.Conv2d(32, 64, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 1)\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 128 * 2 * 2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "    \n",
        "'''\n",
        "class Print(nn.Module):\n",
        "    def forward(self, x):\n",
        "        print(x.size())\n",
        "        return x\n",
        "'''\n",
        "net = Net()\n",
        "net = net.double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MDTwJJETcNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "#adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "XXiGZHVUTcNH",
        "colab_type": "code",
        "colab": {},
        "outputId": "966144a2-8aa2-406d-b8db-f3c5dfd489e2"
      },
      "source": [
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        labels = labels.type(torch.double)\n",
        "        inputs = inputs.type(torch.double) \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs).type(torch.double) \n",
        "        loss = criterion(outputs, labels.type(torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 0.615\n",
            "[2,  2000] loss: 0.589\n",
            "[3,  2000] loss: 0.582\n",
            "[4,  2000] loss: 0.578\n",
            "[5,  2000] loss: 0.576\n",
            "[6,  2000] loss: 0.570\n",
            "[7,  2000] loss: 0.568\n",
            "[8,  2000] loss: 0.566\n",
            "[9,  2000] loss: 0.564\n",
            "[10,  2000] loss: 0.562\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpQ5qlRTcNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save our trained model:\n",
        "PATH = 'wildfire_preset1.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "LMEr8dZGTcNM",
        "colab_type": "code",
        "colab": {},
        "outputId": "ec575138-a353-4ea6-c129-39d968723342"
      },
      "source": [
        "#load back in our saved model\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Smug83f9TcNO",
        "colab_type": "code",
        "colab": {},
        "outputId": "2543582e-12cc-43e3-f1f3-0604572464a0"
      },
      "source": [
        "train_iter = iter(train_loader)\n",
        "sample = train_iter.next()\n",
        "image, label = sample \n",
        "print(image.shape)\n",
        "pred = net(image) # image shape needs to be (batch_size × in_channels × H × W)\n",
        "print('the prediction tensor',pred)\n",
        "print('the prediction shape',pred.shape)\n",
        "print('the label',label)\n",
        "print('The probability of firing', F.softmax(pred, dim=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 6, 8, 8])\n",
            "the prediction tensor tensor([[ 1.7595, -1.4062],\n",
            "        [ 0.3250, -0.0657],\n",
            "        [ 0.9495, -1.5271],\n",
            "        [ 0.3185, -0.1702]], grad_fn=<AddmmBackward>)\n",
            "the prediction shape torch.Size([4, 2])\n",
            "the label tensor([0., 0., 0., 0.])\n",
            "The probability of firing tensor([[0.9595, 0.0405],\n",
            "        [0.5965, 0.4035],\n",
            "        [0.9225, 0.0775],\n",
            "        [0.6198, 0.3802]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrr3eRWFTcNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifier(predicted):\n",
        "    result = torch.zeros(4, 2).type(torch.int)\n",
        "    j = 0\n",
        "    for i in predicted:\n",
        "        if i.data[0] > i.data[1]:\n",
        "            result.data[j, 0] = 1\n",
        "            result.data[j, 1] = 0\n",
        "        else:\n",
        "            result.data[j, 0] = 0\n",
        "            result.data[j, 1] = 1\n",
        "        j+=1\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKMV2U06TcNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = WildfireDataset('test.csv', transform=torch.from_numpy)\n",
        "testloader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hUX6bXunTcNS",
        "colab_type": "code",
        "colab": {},
        "outputId": "9d6f2b4d-b0eb-44e8-ad39-d4e4edd45bfd"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 66 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-7UXITITcNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('fire', 'no fire')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LQM91rtWTcNV",
        "colab_type": "code",
        "colab": {},
        "outputId": "b2eee4a8-d198-4d76-ac25-3c02891d2a20"
      },
      "source": [
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        if list(c.size()) ==[4]:\n",
        "            for i in range(4):\n",
        "                label = labels[i].type(torch.int)\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "        else:\n",
        "            label = labels.type(torch.int)\n",
        "            class_correct[label] += c.item()\n",
        "            class_total[label] += 1\n",
        "            \n",
        "for i in range(2):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of  fire : 95 %\n",
            "Accuracy of no fire : 12 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wCxCY169TcNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    prob_list=[]\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        predicted = F.softmax(outputs, dim=1)\n",
        "        fire_prob = predicted[:,0].numpy()*100\n",
        "        for i in range(len(fire_prob)):\n",
        "            prob_list.append(fire_prob[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Mr6M9J2XTcNY",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ce1f702-eb23-4980-b38b-988c0960631d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(prob_list, density=True, bins=100)  # `density=False` would make counts\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Probaility')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l9KZRpSTcNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define device as the first visible cuda device if CUDA available:\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5qoW2u4TcNd",
        "colab_type": "text"
      },
      "source": [
        "The rest of this section assumes that ``device`` is a CUDA device.\n",
        "\n",
        "Then these methods will recursively go over all modules and convert their\n",
        "parameters and buffers to CUDA tensors:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "Remember that you will have to send the inputs and targets at every step\n",
        "to the GPU too:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "Why dont I notice MASSIVE speedup compared to CPU? Because your network\n",
        "is really small."
      ]
    }
  ]
}